{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import warnings\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.features import *\n",
    "from src.utils import *\n",
    "from src.models import *\n",
    "from src.optimizers import *\n",
    "from src.loss_functions import *\n",
    "from src.dataloaders import *\n",
    "from src.security import NEPTUNE_TOKEN\n",
    "from src.pipeline_functions import *\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "# show all columns\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stocks = [\"SPY\", \"VTV\", \"VUG\", \"VYM\", \"QQQ\", \"VNQ\", \"GLD\", \"AGG\", \"SOXX\", \"OIH\", \"IYT\", \"XLF\", \"XLV\", \"VOX\", \"XLY\", \"XLP\", \"BND\", \"BSV\", \"IEMG\", \"VEA\", \"VWO\"]\n",
    "stocks = sorted(stocks)\n",
    "\n",
    "stock_classes = {'AGG': 'EQUITY', 'GLD': 'COMMODITY', 'IYT': 'EQUITY', 'OIH': 'EQUITY', 'QQQ': 'EQUITY',\n",
    "                 'SOXX': 'EQUITY', 'SPY': 'EQUITY', 'VNQ': 'REAL_ESTATE', 'VOX': 'EQUITY', 'VTV': 'EQUITY',\n",
    "                 'VUG': 'EQUITY', 'VYM': 'EQUITY', 'XLF': 'EQUITY', 'XLP': 'EQUITY', 'XLV': 'EQUITY', 'XLY': 'EQUITY',\n",
    "                 \"BND\": \"FIXED_INCOME\", \"BSV\": \"FIXED_INCOME\", \"IEMG\": \"EQUITY\", \"VEA\": \"EQUITY\", \"VWO\": \"EQUITY\"\n",
    "}\n",
    "\n",
    "classes_color = {'EQUITY': 'salmon', 'COMMODITY': 'cyan', 'FIXED_INCOME': 'lightgreen', \"REAL_ESTATE\": \"lightblue\"}\n",
    "\n",
    "len(stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGG Start of history: 2003-09-29\n",
      "BND Start of history: 2007-04-10\n",
      "BSV Start of history: 2007-04-10\n",
      "GLD Start of history: 2004-11-18\n",
      "IEMG Start of history: 2012-10-24\n",
      "IYT Start of history: 2004-01-02\n",
      "OIH Start of history: 2001-02-26\n",
      "QQQ Start of history: 1999-03-10\n",
      "SOXX Start of history: 2001-07-13\n",
      "SPY Start of history: 1993-01-29\n",
      "VEA Start of history: 2007-07-26\n",
      "VNQ Start of history: 2004-09-29\n",
      "VOX Start of history: 2004-09-29\n",
      "VTV Start of history: 2004-01-30\n",
      "VUG Start of history: 2004-01-30\n",
      "VWO Start of history: 2005-03-10\n",
      "VYM Start of history: 2006-11-16\n",
      "XLF Start of history: 1998-12-22\n",
      "XLP Start of history: 1998-12-22\n",
      "XLV Start of history: 1998-12-22\n",
      "XLY Start of history: 1998-12-22\n"
     ]
    }
   ],
   "source": [
    "path = \"C:\\\\Users\\\\Андрей\\\\Documents\\\\diploma_python\\\\data\"\n",
    "\n",
    "df_adj_close, df_close, df_high, df_low, df_volume = get_data(path, stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features generated and scaled\n",
      "Return features generated\n",
      "Correlation and covariance matrices generated\n",
      "Common index length 2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:07<00:00,  2.86it/s]\n",
      "100%|██████████| 2416/2416 [00:56<00:00, 43.01it/s]\n",
      "100%|██████████| 2416/2416 [00:04<00:00, 543.98it/s]\n",
      "100%|██████████| 2416/2416 [00:04<00:00, 535.72it/s]\n",
      "100%|██████████| 2416/2416 [05:06<00:00,  7.89it/s]\n",
      "100%|██████████| 2416/2416 [05:17<00:00,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrices generated\n",
      "Pipeline finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nodes_matrix, combined_adj_matrix, cov_adj_matrix, future_return, df_return, df_features = features_pipeline(df_adj_close, df_close, df_high, df_low, df_volume, stocks=stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = 1800\n",
    "PERIOD = 90 #max window for features' calculation\n",
    "\n",
    "train_dataset = Dataset(nodes_matrix[:TRAIN], \n",
    "                          combined_adj_matrix[:TRAIN], \n",
    "                          cov_adj_matrix[:TRAIN], \n",
    "                          future_return[:TRAIN])\n",
    "\n",
    "test_dataset = Dataset(nodes_matrix[TRAIN+PERIOD:],\n",
    "                            combined_adj_matrix[TRAIN+PERIOD:],\n",
    "                            cov_adj_matrix[TRAIN+PERIOD:],\n",
    "                            future_return[TRAIN+PERIOD:])\n",
    "\n",
    "len(test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = {0: 10, 1: 100, 2: 500, 3: 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-43\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 2 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 2 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-43/metadata\n",
      "0 is trained\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-44\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 2 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 2 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-44/metadata\n",
      "1 is trained\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-45\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 4 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 4 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-45/metadata\n",
      "2 is trained\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-46\n",
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "All 0 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/aibabynin/graphs/e/GRAP-46/metadata\n",
      "3 is trained\n"
     ]
    }
   ],
   "source": [
    "model_dic = {}\n",
    "SEED = 45\n",
    "\n",
    "for i in range(4):\n",
    "    set_seed(SEED)\n",
    "\n",
    "    model = GrossModel(num_features=23, num_relations=5, num_assets=21, sample_size=10, pred_window=5, n_heads=1, storage_size=cases[i],\n",
    "                       train_gamma=False, gamma=0.01)\n",
    "    \n",
    "    optim = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "    _, _ = train(model, optim, train_dataset, epochs=4,\n",
    "                                eval_func='sharpe_loss', exp_name=f'exp_2705_per_v{i}', neptune_token=NEPTUNE_TOKEN,\n",
    "                                neptune_project=\"aibabynin/graphs\", tags=[\"weights_constraints\"], per=False if i==3 else True)\n",
    "    \n",
    "    model_dic[i] = {\"model\": model,\n",
    "                    \"optimizer\": optim}\n",
    "\n",
    "    print(f\"{i} is trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511/511 [00:22<00:00, 22.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511/511 [00:25<00:00, 20.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511/511 [00:25<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 is evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 511/511 [00:25<00:00, 20.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 is evaluated\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4):\n",
    "    test_weights_matrix = evaluate(model_dic[i]['model'], test_dataset)\n",
    "    model_dic[i]['test_weights_matrix'] = test_weights_matrix\n",
    "    \n",
    "    print(f\"{i} is evaluated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = df_return.iloc[TRAIN + PERIOD + model.sample_size + model.pred_window:].values\n",
    "index = df_return.iloc[TRAIN + PERIOD + model.sample_size + model.pred_window:].index\n",
    "\n",
    "returns_matrix = np.zeros((4, len(ret)))\n",
    "\n",
    "for i in range(4):\n",
    "\n",
    "    returns_matrix[i] = (ret * model_dic[i]['test_weights_matrix']).sum(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m plt\u001b[39m.\u001b[39mstyle\u001b[39m.\u001b[39muse(\u001b[39m'\u001b[39m\u001b[39mggplot\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[0;32m      3\u001b[0m _ \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mplot(index, (ret\u001b[39m.\u001b[39mmean(\u001b[39m1\u001b[39m)\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcumprod()\u001b[39m-\u001b[39m \u001b[39m1\u001b[39m, color\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEqually weighted\u001b[39m\u001b[39m'\u001b[39m, linewidth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(8, 6))\n",
    "_ = plt.plot(index, (ret.mean(1)+1).cumprod()- 1, color='green', label='Equally weighted', linewidth=2)\n",
    "\n",
    "for i in range(4):\n",
    "    _ = plt.plot(index, (returns_matrix[i]+1).cumprod()- 1, alpha=0.7, label=f'PER = {cases[i]}', linestyle='--')\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "plt.xlabel('Date', fontsize=11, fontname='Georgia')\n",
    "plt.ylabel('Cumulative return', fontsize=11, fontname='Georgia')\n",
    "plt.title('Portfolio return under different PER buffers', fontsize=13, fontname='Georgia')\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1), title='Scanarios', fontsize=9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    torch.save(model_dic[i]['model'].state_dict(), f\"model_buffer_{i}_sr.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER = 100: 435 days out of 511 days, pct: 0.85\n",
      "PER = 100: Sharpe ratio: 0.72, return: 0.17\n",
      "PER = 100: Outperformance on positive days: 0.81, days 211\n",
      "PER = 100: Outperformance on negative days: 0.89, days 224\n",
      "PER = 500: 487 days out of 511 days, pct: 0.95\n",
      "PER = 500: Sharpe ratio: 1.02, return: 0.25\n",
      "PER = 500: Outperformance on positive days: 0.95, days 245\n",
      "PER = 500: Outperformance on negative days: 0.96, days 242\n",
      "PER = 0: 395 days out of 511 days, pct: 0.77\n",
      "PER = 0: Sharpe ratio: 0.14, return: 0.03\n",
      "PER = 0: Outperformance on positive days: 0.78, days 201\n",
      "PER = 0: Outperformance on negative days: 0.77, days 194\n"
     ]
    }
   ],
   "source": [
    "cum_ret_b = (ret.mean(1)+1).cumprod()- 1\n",
    "\n",
    "for i in range(1, 4):\n",
    "    days_outperformance = ((returns_matrix[i]+1).cumprod()- 1 > cum_ret_b)\n",
    "    print(f\"PER = {cases[i]}: {days_outperformance.sum()} days out of {len(cum_ret_b)} days, pct: {days_outperformance.sum()/len(cum_ret_b):.2f}\")\n",
    "    std = returns_matrix[i].std() * np.sqrt(len(returns_matrix[i]))\n",
    "    p_ret = ((returns_matrix[i]+1).cumprod()- 1)[-1]\n",
    "    sharpe = p_ret / std\n",
    "    print(f\"PER = {cases[i]}: Sharpe ratio: {sharpe:.2f}, return: {p_ret:.2f}\")\n",
    "    out_high = days_outperformance[ret.mean(1)>0].sum() / (ret.mean(1)>0).sum()\n",
    "    out_low = days_outperformance[ret.mean(1)<0].sum() / (ret.mean(1)<0).sum()\n",
    "    print(f\"PER = {cases[i]}: Outperformance on positive days: {out_high:.2f}, days {days_outperformance[ret.mean(1)>0].sum()}\")\n",
    "    print(f\"PER = {cases[i]}: Outperformance on negative days: {out_low:.2f}, days {days_outperformance[ret.mean(1)<0].sum()}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5403"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ret>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.mean(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diploma_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
